{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KrNfVNueNhR"
      },
      "source": [
        "# This notebook contains the source code of the CS 521 class project. Specifically, this notebook contains the code for making an LLM roleplay the neighbor and landlord in the neighbor and landlord scenario respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgL1yLLS09mP",
        "outputId": "c97b16cd-83be-4457-b790-2b1cc8c6bcc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onU41i8g1J3M"
      },
      "outputs": [],
      "source": [
        "# Install the required libraries\n",
        "! pip -q install transformers\n",
        "! pip install torchmetrics\n",
        "! pip install evaluate\n",
        "! pip install bert_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Y1XcsqgXBQ"
      },
      "source": [
        "Let's move to the desired folder in which we will store all our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHNacD0k1HI3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/RolePlay\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVSTlysV2jaM"
      },
      "source": [
        "Try to chat with LLM without fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "8c221c0b37db4215bc643f6055959ce0",
            "2e6666dd508f4dd280fbcac25778267e",
            "bb8b0f6f3f41462b87e21e539b475b6e",
            "346e4c93a18b496dbf37367a6ae4ff92",
            "b69cdbac44584017a32321486aea087b",
            "602d24ba13aa4abd856d480ad0d32668",
            "16f27aef8dbf42eeae0794f48fddef3c",
            "ce8d746d74ac492882ab0783a29e8ff1",
            "23e444a2f11e4b418ae433865fc046f3",
            "3e868357bc8145629fc52473e877053c",
            "510e99d041d54ccaa522f7acae015131",
            "f55ecaeb591e4279a00f472d64f8cbc3",
            "c2367396960a4be3a83a2b3dc6e3544f",
            "aede6c3349e3468fac56f9a035accfb2",
            "893551ca19a4483895978e6173c1e81d",
            "142c80ea19784b309a3116ecda843886",
            "442a48e64e584eacab67e84ebd66d304",
            "9420aef7ff904c148e051bb5ddd66636",
            "c2233df4925a4553b4f7db0a27a08ac8",
            "538db49a4a1c44c199f185802f2c4c18",
            "613afcfec84c40828ca5f3622d321772",
            "5cf307b69ed046edb014f783daeb9803",
            "0bcb3976d6794529841869fce0d6feb3",
            "4cdfa2a0419d40499889314422bd30f0",
            "6b2a40af5a254cd5abb71158d566dcba",
            "9b5fcc7dbd934ca78fb3933387e9e571",
            "494a4a35a83f454e93d7f0dae95416d7",
            "dfdf8c4c535349cc94c66686ef0c508a",
            "abdadf94f9094da9a616af92377e69b8",
            "1b0a7922b94b4f5eb74fd15b383dd393",
            "22fe5170eb23495e8bbc6be40e4bdfcf",
            "1ab3188243444284a45a67add4ee3e60",
            "454e112dce4a43938d3aa0854b6f29a9",
            "d2ecce3f871b410fad5c8bcd86add663",
            "4ec5d0fb8c70445798d7ffe90974e07e",
            "ccca28c7fd72491a80d81f1b490291af",
            "2187193846674d2bb377bf614e5eedc8",
            "15b12e98180e49b0a309e7369b70bfeb",
            "0b338d2f1e524d1e908be0e2c0289c64",
            "d806ddc558f5411aba99813a5eaf8853",
            "0347e50d2e124b71882437f0703be8cd",
            "aad5d4d487084ebf9d025549ea89328a",
            "b3dd1fe1311047feb837b512a47979ea",
            "472639a75c6f4316872fdc3f802c7d66",
            "31edf74da1924269a7a0169dec572eb6",
            "f38a4b6754b54c64a82957b7b7ac0e56",
            "be89d71b7ccf4322923811ce6122baad",
            "90ce1fee6c32460c8b99048355009df3",
            "cb9b69474c464e06b46a9361c7d18670",
            "fa315336cf0143efbd4c16dc1e452713",
            "1d293b58999b45d8bc14491f91b8872d",
            "f8de0a128a43403486b76c928dd27fdd",
            "7d88a0439e914e5aacb6765db7fb5df1",
            "e3189e87a6b24de7b194ae4d326a89fa",
            "ced90b7400814f3f8c4e54b683fa0d13",
            "81e10855a3c049b58d09fd2b2aa4696c",
            "ff1bc73d07f449a8bbdffc88c9270b5e",
            "cbbe6b84de3f4f5abc0063a66efac187",
            "01d4765b90dc4d10bc01ce9df1cf3c86",
            "bec7560c6094471abca139493113abdd",
            "8dca9eb853dc4103a18b46d62dc1bb19",
            "d7206b2d41df45c797c9f1170a3dcb70",
            "dbd8e0a3ea0d46ecb7d58058582e4257",
            "529defb66b284c11ae1b3fa5ad6de96b",
            "abb557be85e94afd890d6e7cdbded5e0",
            "f7bd35bfad384344befdc26c28722d57",
            "faf803620b0b4954b4961b8a00e1c95a",
            "676b70b05d5741d0b233ea687e4e3642",
            "12f3f95332204c5d970bf9d202ff6f33",
            "f04d81c2aebc48fbb62511566761de13",
            "b6a90c5735f34d57810a97dc01a33e08",
            "ff52187f931848e7a6117a8092227292",
            "66a6200111604397b1870842dbcd77f8",
            "d8616d0455a24a098b79b0df93d34072",
            "42326deb23a445b5b697d7af7a9822e7",
            "ac1b5813833349568d54399c0792ae6b",
            "69f21fe2809b42bf8d945755dc7161e7"
          ]
        },
        "id": "w6qrl7_SvPKg",
        "outputId": "1b269c4e-bdc6-4a23-9288-7354979bc899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c221c0b37db4215bc643f6055959ce0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f55ecaeb591e4279a00f472d64f8cbc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bcb3976d6794529841869fce0d6feb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2ecce3f871b410fad5c8bcd86add663"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31edf74da1924269a7a0169dec572eb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81e10855a3c049b58d09fd2b2aa4696c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faf803620b0b4954b4961b8a00e1c95a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModelForCausalLM\n",
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import re\n",
        "# Replace TinyLlama/TinyLlama-1.1B-Chat-v1.0 with any other LLM trained with Causal LM objective\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "tokenizer.pad_token = '[PAD]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAaboKvgozKK",
        "outputId": "860675bd-3518-4abd-cdf8-fd81ccf9568d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "else:\n",
        "  print(\"Not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjZaN5ilgd-z"
      },
      "outputs": [],
      "source": [
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens\n",
        "    chat_history_ids = model.generate(\n",
        "    bot_input_ids, max_length=1000,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAy2OBMW6QyD"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/L3WevKXIKFDaZBvV8Q/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "Not bad but not too impressive. We will fix it with fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuzSROqxjUKM"
      },
      "source": [
        "## Model initial configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC3qNlfp30aU"
      },
      "source": [
        "Let's train our own chatbot. For start, we will need basic configuration and a dataset.\n",
        "Configuration and training scripts are mostly based on this [script](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) from Huggingface and great [tutorial](https://nathancooper.io/i-am-a-nerd/chatbot/deep-learning/gpt2/2020/05/12/chatbot-part-1.html) from Nathan Cooper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g91QzdqU2haO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
        "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
        "using a masked language modeling (MLM) loss.\n",
        "\"\"\"\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    AutoModelForCausalLM\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "# Configs\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set the arguments here**"
      ],
      "metadata": {
        "id": "W4z-NMSvFGkv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utprDGf06OVt"
      },
      "outputs": [],
      "source": [
        "# Args to allow for easy convertion of python script to notebook\n",
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.output_dir = '/content/drive/MyDrive/RolePlay/TinyLlama-1.1B-Chat-v1.0'  # set the output directory here\n",
        "        self.model_type = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0' # set the model type here\n",
        "        self.model_name_or_path = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0' # set the model id here\n",
        "        self.config_name = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
        "        self.tokenizer_name = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0' # set the tokenizer name here\n",
        "        self.cache_dir = '/content/drive/MyDrive/RolePlay/cached' # set the path to cache directory here\n",
        "        self.block_size = 512\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = False\n",
        "        self.per_gpu_train_batch_size = 2\n",
        "        self.per_gpu_eval_batch_size = 2\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-6\n",
        "        self.weight_decay = 1e-2 # was 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 5 # was earlier 3\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.logging_steps = 1000\n",
        "        self.save_steps = 3500\n",
        "        self.save_total_limit = 1\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.no_cuda = False\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.should_continue = False\n",
        "        self.seed = 42\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = False\n",
        "        self.fp16_opt_level = 'O1'\n",
        "        # Set paths to the folder where each dataset is stored.\n",
        "        self.BD_Scene1 = '/content/drive/MyDrive/RolePlay/SSPA Data/SSPA Data/Complete transcript txt/BD_SC_1' # Bipolar Scene 1\n",
        "        self.BD_Scene2 = '/content/drive/MyDrive/RolePlay/SSPA Data/SSPA Data/Complete transcript txt/BD_SC_2' # Bipolar Scene 2\n",
        "        self.HC_Scene1 = '/content/drive/MyDrive/RolePlay/SSPA Data/SSPA Data/Complete transcript txt/HC_SC_1' # Healthy Control Scene 1\n",
        "        self.HC_Scene2 = '/content/drive/MyDrive/RolePlay/SSPA Data/SSPA Data/Complete transcript txt/HC_SC_2' # Healthy Control Scene 2\n",
        "        self.SZ_Scene1 = '/content/drive/MyDrive/RolePlay/SSPA Data/SSPA Data/Complete transcript txt/SZ_SC_1' # Schizophrenia Scene 1\n",
        "        self.SZ_Scene2 = '/content/drive/MyDrive/RolePlay/SSPA Data/SSPA Data/Complete transcript txt/SZ_SC_2' # Schizophrenia Scene 2\n",
        "        self.test_size = 0.15\n",
        "        self.context_size = 800\n",
        "\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qYqlTe9yx2"
      },
      "source": [
        "## Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSrxI1Ps4GIM",
        "outputId": "64fec049-5e71-415e-c0b3-c53c190dbed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/RolePlay\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBeM8pvEjigq"
      },
      "source": [
        "Split our dataset into a training and test parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1CeutVVlL85"
      },
      "outputs": [],
      "source": [
        "# trn_df, val_df = train_test_split(df, test_size = 0.1)\n",
        "# trn_df.head()\n",
        "\n",
        "# This function will create a list of filenames (complete filename including their path) given the directory path\n",
        "def list_files(directory):\n",
        "    files = []  # List to store file names\n",
        "    # Iterate over all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        filepath = os.path.join(directory, filename)  # Get the full file path\n",
        "        if os.path.isfile(filepath):  # Check if the path is a file\n",
        "            files.append(filepath)  # Add the file path to the list\n",
        "    return files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment the next 4 cells once the train and test data frames are prepared"
      ],
      "metadata": {
        "id": "pomlt2qgFnH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq1MaQkSIQkU"
      },
      "outputs": [],
      "source": [
        "transcript_path = '/content/drive/MyDrive/RolePlay/SSPA Data/SSPA Data/Complete transcript txt/All transcripts'\n",
        "BD_SC1_filenames = list_files(args.BD_Scene1)\n",
        "BD_SC2_filenames = list_files(args.BD_Scene2)\n",
        "HC_SC1_filenames = list_files(args.HC_Scene1)\n",
        "HC_SC2_filenames = list_files(args.HC_Scene2)\n",
        "SZ_SC1_filenames = list_files(args.SZ_Scene1)\n",
        "SZ_SC2_filenames = list_files(args.SZ_Scene2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhC_zUqGChra"
      },
      "outputs": [],
      "source": [
        "# trn_df and val_df are list of filenames(complete names with path)\n",
        "BD_SC1_trn_df, BD_SC1_val_df = train_test_split(BD_SC1_filenames, test_size = args.test_size)\n",
        "BD_SC2_trn_df, BD_SC2_val_df = train_test_split(BD_SC2_filenames, test_size = args.test_size)\n",
        "HC_SC1_trn_df, HC_SC1_val_df = train_test_split(HC_SC1_filenames, test_size = args.test_size)\n",
        "HC_SC2_trn_df, HC_SC2_val_df = train_test_split(HC_SC2_filenames, test_size = args.test_size)\n",
        "SZ_SC1_trn_df, SZ_SC1_val_df = train_test_split(SZ_SC1_filenames, test_size = args.test_size)\n",
        "SZ_SC2_trn_df, SZ_SC2_val_df = train_test_split(SZ_SC2_filenames, test_size = args.test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQCsd6NXMrW8"
      },
      "outputs": [],
      "source": [
        "trn_df = BD_SC1_trn_df + BD_SC2_trn_df + HC_SC1_trn_df + HC_SC2_trn_df + SZ_SC1_trn_df + SZ_SC2_trn_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f1wxLoLxiHm"
      },
      "outputs": [],
      "source": [
        "torch.save(trn_df,'/content/drive/MyDrive/RolePlay/trainset.pkl')\n",
        "\n",
        "torch.save(BD_SC1_val_df, '/content/drive/MyDrive/RolePlay/BD_SC1_val.pkl')\n",
        "torch.save(BD_SC2_val_df, '/content/drive/MyDrive/RolePlay/BD_SC2_val.pkl')\n",
        "torch.save(HC_SC1_val_df, '/content/drive/MyDrive/RolePlay/HC_SC1_val.pkl')\n",
        "torch.save(HC_SC2_val_df, '/content/drive/MyDrive/RolePlay/HC_SC2_val.pkl')\n",
        "torch.save(SZ_SC1_val_df, '/content/drive/MyDrive/RolePlay/SZ_SC1_val.pkl')\n",
        "torch.save(SZ_SC2_val_df, '/content/drive/MyDrive/RolePlay/SZ_SC2_val.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaWePXL-_pQl"
      },
      "outputs": [],
      "source": [
        "# print(len(trn_df))\n",
        "#print(len(val_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGBVEOCsW5RY"
      },
      "outputs": [],
      "source": [
        "# print(trn_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86F3WhnFO4H8"
      },
      "source": [
        "Now will convert our dataset in a format suitable for our model. Basically we will concatenate responses in one string for each conversation ending with the interviewer's response (additionally we will add special 'end of string' token between responses, so the model will understand end of each response in a string).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phTyg8C7ygSq"
      },
      "outputs": [],
      "source": [
        "def constructConvDataset(filepath, prompt_string, tokenizer):\n",
        "  datasetList=[] # This is a list of lists, where each list represents a part of conversation(in the form of token_ids)\n",
        "                 # beginning with the prompt and ending with the interviewer's turn\n",
        "\n",
        "  utterances = []  # This is a list of 2-tuples of (int, string), where the integer in the tuple represents if the\n",
        "                   #string is of interviewer(1) or patient(0). Each string represents either patient's turn or the\n",
        "                   # interviewer's turn\n",
        "  current_utterance = ''  # Variable to store the current utterance\n",
        "  current_label = None  # Variable to store the current label (0 for patient, 1 for interviewer)\n",
        "  end_of_conversation = False  # Flag to indicate if the end cue is encountered\n",
        "\n",
        "  # Open the text file for reading\n",
        "  with open(filepath, 'r', encoding='utf-8') as file:\n",
        "      # Iterate over each line in the file\n",
        "      for line in file:\n",
        "          #print(\"line: \", line)\n",
        "          line = line.strip()  # Remove leading/trailing whitespaces\n",
        "          if end_of_conversation:  # Stop parsing if the end cue is encountered\n",
        "              break\n",
        "          elif re.match(r'^#+.*', line):  # Check if the line contains '#' characters\n",
        "              end_of_conversation = True  # Set the flag if the end cue is encountered\n",
        "              continue\n",
        "          elif line.startswith('Interviewer:'):\n",
        "              if (current_utterance and (current_label == 0) ):  # If there's a previous utterance, store it\n",
        "                  utterances.append((current_label, current_utterance))\n",
        "                  current_utterance = line[len('Interviewer:'):].strip()  # Extract the utterance text\n",
        "              elif(current_utterance and (current_label == 1)):\n",
        "                current_utterance += ' ' + line[len('Interviewer:'):].strip()  # Extract the utterance text\n",
        "              else:\n",
        "                current_utterance = line[len('Interviewer:'):].strip()\n",
        "\n",
        "              current_label = 1  # Set label to 1 for interviewer\n",
        "          elif line.startswith('Patient:'):\n",
        "              if (current_utterance and (current_label == 1) ) :  # If there's a previous utterance, store it\n",
        "                  utterances.append((current_label, current_utterance))\n",
        "                  current_utterance = line[len('Patient:'):].strip()\n",
        "              elif(current_utterance and (current_label == 0)):\n",
        "                current_utterance += ' ' + line[len('Patient:'):].strip()  # Extract the utterance text\n",
        "              else:\n",
        "                current_utterance = line[len('Patient:'):].strip()\n",
        "\n",
        "              current_label = 0  # Set label to 0 for patient\n",
        "          elif line.startswith('+++'):  # Skip lines with timestamps\n",
        "              continue\n",
        "          elif line and current_utterance:  # If the line is not empty and there is an ongoing utterance\n",
        "              current_utterance += ' ' + line.strip()  # Concatenate with the previous line\n",
        "\n",
        "  # Append the last utterance to the list\n",
        "  if current_utterance:\n",
        "      utterances.append((current_label, current_utterance))\n",
        "  # print(\"Utterances: \", utterances)\n",
        "  # print(\"filepath: \", filepath)\n",
        "\n",
        "  start_index = 0\n",
        "  end_index = 0\n",
        "  if(utterances[0][0] == 0): # First utterance is of patient\n",
        "    end_index = 1\n",
        "\n",
        "\n",
        "  flatten = lambda somelist: [item for sublist in somelist for item in sublist]\n",
        "  # print(\"start_index: \", start_index)\n",
        "  # print(\"end_index: \", end_index)\n",
        "  # print(\"len(utterances): \", len(utterances))\n",
        "  # print(\"filepath: \", filepath)\n",
        "  utterance_list = [tokenizer.encode(prompt_string)] + [[tokenizer.eos_token_id]] + [tokenizer.encode(utterances[x][1]) + [tokenizer.eos_token_id] for x in range(start_index,end_index+1)]\n",
        "  utterance_list = flatten(utterance_list) #List of running utterance token_ids\n",
        "\n",
        "  datasetList.append(utterance_list)\n",
        "\n",
        "\n",
        "  end_index+=2\n",
        "  while(end_index<len(utterances)):\n",
        "    utterance_list = utterance_list + tokenizer.encode(utterances[end_index-1][1]) + [tokenizer.eos_token_id] + tokenizer.encode(utterances[end_index][1]) + [tokenizer.eos_token_id]\n",
        "    newlen = len(utterance_list)\n",
        "    if(newlen>args.context_size):\n",
        "\n",
        "      while(start_index < end_index and newlen>args.context_size):\n",
        "\n",
        "        start_index+=1\n",
        "        if(start_index<end_index):\n",
        "          utterance_list = tokenizer.encode(prompt_string) + [tokenizer.eos_token_id]\n",
        "          for myind in range(start_index,end_index+1):\n",
        "            utterance_list+=tokenizer.encode(utterances[myind][1]) +[tokenizer.eos_token_id]\n",
        "\n",
        "          #utterance_list = [tokenizer.encode(prompt_string)] + [tokenizer.encode(utterances[x][1]) + [tokenizer.eos_token_id] for x in range(start_index,end_index+1)]\n",
        "\n",
        "          #utterance_list = flatten(utterance_list)\n",
        "          newlen = len(utterance_list)\n",
        "        else:\n",
        "          break\n",
        "\n",
        "\n",
        "    datasetList.append(utterance_list)\n",
        "    end_index+=2\n",
        "\n",
        "  return datasetList"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the Neighbor and Landlord prompts"
      ],
      "metadata": {
        "id": "0h4CjFCCGJmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeENLf9GXnVy"
      },
      "outputs": [],
      "source": [
        "promptStringNeighbor = \"I want you to roleplay a neighbor who has moved in to a new neighborhood. If your neighbor's utterance are related to the utterance you have already seen, please try to reuse the original response lines.\"\n",
        "promptStringLandlord = \"I want you to roleplay a landlord who is conversing with a tenant. If your tenant's utterance are related to the utterance you have already seen, please try to reuse the original response lines. The situation is that tenant had complained to you about a leak earlier but that has not been fixed yet.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX7jeWpYmOe_"
      },
      "outputs": [],
      "source": [
        "# Given a row(list of list of strings, where each string is a dialogue in a turn. The order of dialogues in the row is\n",
        "# in reverse order, i.e. the most recent dialogue first, and the oldest dialogue last.), the function returns a single\n",
        "# list where in which each element is the token id, and the individual dialogues are separated by the eos token. The\n",
        "# order of dialogues in the returned list is oldest to newest, where the oldest dialogue is first and the most recent\n",
        "# dialogue is last, and the last dialogue is the response.\n",
        "def construct_conv(row, tokenizer, eos = True):\n",
        "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n",
        "    conv = flatten(conv)\n",
        "    return conv\n",
        "\n",
        "# This class is used to create a custom dataset. Since args.overwrite_cache is true, the __init__ method overwrites the\n",
        "# cached_features_file and creates a list of lists using the construct_conv function. The dataframe corresponding to the\n",
        "# list of lists is a parameter of the init method. df is a list of strings, where each string\n",
        "# represents a filename.\n",
        "class ConversationDataset(Dataset):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n",
        "\n",
        "        block_size = block_size - (tokenizer.model_max_length - tokenizer.max_len_single_sentence)\n",
        "        print(\"Effective block size: \", block_size)\n",
        "\n",
        "        directory = args.cache_dir\n",
        "        cached_features_file = os.path.join(\n",
        "            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n",
        "        )\n",
        "\n",
        "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
        "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"rb\") as handle:\n",
        "                self.examples = pickle.load(handle)\n",
        "        else:\n",
        "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
        "\n",
        "            self.examples = [] # List of lists, where each list is a part of conversation\n",
        "                               # represented as token ids\n",
        "\n",
        "            # for _, row in df.iterrows():\n",
        "            #     conv = construct_conv(row, tokenizer)\n",
        "            #     self.examples.append(conv)\n",
        "\n",
        "            for fil in df:\n",
        "              if(\"Scene 1\" in fil):\n",
        "                #print(fil)\n",
        "                conv_list = constructConvDataset(fil, promptStringNeighbor, tokenizer)\n",
        "                self.examples += conv_list\n",
        "              else:\n",
        "                conv_list = constructConvDataset(fil, promptStringLandlord, tokenizer)\n",
        "                self.examples += conv_list\n",
        "\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            #Check if directory structure exists before using pickle.dump\n",
        "            cached_directory = os.path.dirname(cached_features_file)\n",
        "            if not os.path.exists(cached_directory):\n",
        "                os.makedirs(cached_directory)\n",
        "            with open(cached_features_file, \"wb\") as handle:\n",
        "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.examples[item], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naaRHoXgnStq"
      },
      "outputs": [],
      "source": [
        "# Cacheing and storing of data/checkpoints\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n",
        "    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "# This function returns sorted checkpoints in the directory given by args.output_dir. The checkpoints are either sorted\n",
        "# by their modification time or by the number in the checkpoint file name. For example, if the checkpoints are\n",
        "# \"checkpoint-1\", and \"checkpoint-2\", then the function will return a list of checkpoint file names:\n",
        "# [\"checkpoint-1\", \"checkpoint-2\"]\n",
        "\n",
        "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
        "    ordering_and_checkpoint_path = []\n",
        "\n",
        "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
        "\n",
        "    for path in glob_checkpoints:\n",
        "        if use_mtime:\n",
        "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
        "        else:\n",
        "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
        "            if regex_match and regex_match.groups():\n",
        "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
        "\n",
        "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
        "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
        "    return checkpoints_sorted\n",
        "\n",
        "# This method deletes checkpoints if the number of checkpoints in the directory given by args.output_dir\n",
        "# are greater than the number given by args.save_total_limit\n",
        "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
        "    if not args.save_total_limit:\n",
        "        return\n",
        "    if args.save_total_limit <= 0:\n",
        "        return\n",
        "\n",
        "    # Check if we should delete older checkpoint(s)\n",
        "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
        "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
        "        return\n",
        "\n",
        "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
        "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
        "    for checkpoint in checkpoints_to_be_deleted:\n",
        "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
        "        shutil.rmtree(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkvMNnrnVHQw"
      },
      "source": [
        "# Define evaluation metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0iVvqP9-ak1"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hTcbmLrCt2l"
      },
      "outputs": [],
      "source": [
        "#goldLabels, and generatedoutputs are lists of token ids that are passed during the evaluate method\n",
        "def calculate_cosine(goldLabels, generatedoutputs, decoderTokenizer):\n",
        "  device = torch.device(\"cuda\")\n",
        "  goldLabelsDecoded = list(map(lambda l: decoderTokenizer.decode(l,skip_special_tokens = True), goldLabels ))\n",
        "  goldLabelsDecoded = torch.tensor(goldLabelsDecoded)\n",
        "  goldLabelsDecoded = goldLabelsDecoded.to(device)\n",
        "\n",
        "  generatedDecoded =  list(map(lambda l: decoderTokenizer.decode(l,skip_special_tokens = True), generatedoutputs ))\n",
        "  generatedDecoded = torch.tensor(generatedDecoded)\n",
        "  generatedDecoded = generatedDecoded.to(device)\n",
        "\n",
        "\n",
        "  debertaTokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "  debertaModel = AutoModel.from_pretrained(\"microsoft/deberta-base\")\n",
        "  debertaModel.to(device)\n",
        "\n",
        "  goldInputs = debertaTokenizer(goldLabelsDecoded, return_tensors=\"pt\",padding=\"longest\")\n",
        "  generatedInputs = debertaTokenizer(generatedDecoded, return_tensors=\"pt\",padding=\"longest\")\n",
        "\n",
        "  debertaGoldOutputs = debertaModel(**goldInputs)\n",
        "  debertaGeneratedOutput = debertaModel(**generatedInputs)\n",
        "\n",
        "  goldOutputHiddenState = debertaGoldOutputs.last_hidden_state\n",
        "  generatedOutputHiddenState = debertaGeneratedOutput.last_hidden_state\n",
        "\n",
        "  goldOutputEmbedding = goldOutputHiddenState[:,0,:]\n",
        "  generatedOutputEmbedding = generatedOutputHiddenState[:,0,:]\n",
        "\n",
        "  return torch.mean(torch.nn.functional.cosine_similarity(goldOutputEmbedding, generatedOutputEmbedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ejumuf2TeJi"
      },
      "outputs": [],
      "source": [
        "#goldLabels, and generatedoutputs are lists of token ids that are passed during the evaluate method\n",
        "def calculate_rouge(goldLabels, generatedoutputs, decoderTokenizer):\n",
        "  goldLabelsdecoded = list(map(lambda l: decoderTokenizer.decode(l,skip_special_tokens = True), goldLabels ))\n",
        "  generatedDecoded =  list(map(lambda l: decoderTokenizer.decode(l,skip_special_tokens = True), generatedoutputs ))\n",
        "\n",
        "  # print(goldLabelsdecoded[0:3])\n",
        "  # print(generatedDecoded[0:3])\n",
        "  rouge = ROUGEScore(rouge_keys=('rouge1', 'rougeL'))\n",
        "\n",
        "  return rouge(generatedDecoded, goldLabelsdecoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abi54ZZ8bfWW"
      },
      "outputs": [],
      "source": [
        "def calculate_bert_score(goldLabels, generatedoutputs, decoderTokenizer):\n",
        "  goldLabelsdecoded = list(map(lambda l: decoderTokenizer.decode(l,skip_special_tokens = True), goldLabels ))\n",
        "  generatedDecoded =  list(map(lambda l: decoderTokenizer.decode(l,skip_special_tokens = True), generatedoutputs ))\n",
        "\n",
        "  print(\"goldLabelsdecoded: \", goldLabelsdecoded)\n",
        "  print(\"generatedDecoded: \", generatedDecoded)\n",
        "  from evaluate import load\n",
        "  bertscore = load(\"bertscore\")\n",
        "\n",
        "  glempCount=0\n",
        "  for l in goldLabelsdecoded:\n",
        "    if(len(l) == 0):\n",
        "      glempCount+=1\n",
        "\n",
        "  print(\"Empty target sentence count: \", glempCount)\n",
        "\n",
        "  # fulCount=0\n",
        "  # for l in goldLabelsdecoded:\n",
        "  #   if(len(l)>0):\n",
        "  #     print(\"Printing string: \", l)\n",
        "  #     fulCount+=1\n",
        "\n",
        "  # print(\"Full target sentences: \", fulCount)\n",
        "\n",
        "  glempCountPred=0\n",
        "  for l in generatedDecoded:\n",
        "    if(len(l) == 0):\n",
        "      glempCountPred+=1\n",
        "\n",
        "  print(\"Empty predicted sentence count: \", glempCountPred)\n",
        "\n",
        "  # fulCountPred=0\n",
        "  # for l in generatedDecoded:\n",
        "  #   if(len(l)>0):\n",
        "  #     print(\"Printing string: \", l)\n",
        "  #     fulCountPred+=1\n",
        "\n",
        "  # print(\"Full predicted sentences: \", fulCountPred)\n",
        "\n",
        "\n",
        "  results = bertscore.compute(predictions=generatedDecoded, references=goldLabelsdecoded, model_type=\"microsoft/deberta-base\")\n",
        "  for k in results:\n",
        "    # print(type(results[k][0]))\n",
        "    # print(results[k])\n",
        "    if(k!='hashcode'):\n",
        "      results[k] = sum(results[k])/len(results[k])\n",
        "  return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahOtZy71zX-I"
      },
      "source": [
        "# **Train & Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXzKlXHeu0Mb"
      },
      "outputs": [],
      "source": [
        "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "\n",
        "    # Should use tokenizer's padding mechanism instead of own.\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    # add_special_tokens_(model, tokenizer)\n",
        "\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if (\n",
        "        args.model_name_or_path\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
        "        try:\n",
        "            # set global_step to gobal_step of last saved checkpoint from model path\n",
        "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
        "            global_step = int(checkpoint_suffix)\n",
        "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "        except ValueError:\n",
        "            logger.info(\"  Starting fine-tuning.\")\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproducibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            # labels = []\n",
        "\n",
        "            # for example in batch:\n",
        "            #   example = reversed(example)\n",
        "            #   current_example = [tokenizer.eos_token_id]\n",
        "            #   ind = 1\n",
        "            #   while(ind<len(example)):\n",
        "            #     if(example[ind] == tokenizer.eos_token_id):\n",
        "            #       break\n",
        "            #     current_example.append(example[ind])\n",
        "            #     ind+=1\n",
        "            #   current_example+=[-100]*(len(example)-len(current_example))\n",
        "            #   current_example = reversed(current_example)\n",
        "            #   labels.append(current_example)\n",
        "\n",
        "            # Initialize an empty list to store labels\n",
        "\n",
        "            labels = []\n",
        "            attention_masks = []\n",
        "\n",
        "            #print(\"batch.size(): \", batch.size())\n",
        "            # Iterate over each example in the batch\n",
        "            for example in batch:\n",
        "                # Reverse the example\n",
        "                #print(\"example: \", example)\n",
        "                example = torch.flip(example,[0])\n",
        "                # Find the indices of eos_token_id in the reversed example\n",
        "                eos_indices = [i for i, x in enumerate(example) if x == tokenizer.eos_token_id]\n",
        "                # Check if there are at least two occurrences of eos_token_id\n",
        "                    # Get the index of the second occurrence of eos_token_id\n",
        "                idx0 = eos_indices[0]\n",
        "                idx1 = eos_indices[1]\n",
        "                # Create the current example list\n",
        "                current_example = torch.cat([torch.full((idx0,),-100),example[idx0:idx1]])\n",
        "                # Pad the current example list with -100\n",
        "                current_example = torch.cat([current_example, torch.full((len(example) - len(current_example),),-100)] )\n",
        "                attention_mask = torch.cat([torch.full((idx0,),0),torch.full((len(example) - idx0,),1)])\n",
        "\n",
        "                #current_example = torch.cat([current_example, torch.full((len(example) - len(current_example),),-100)] )\n",
        "                # Reverse the current example list\n",
        "                current_example = torch.flip(current_example,[0])\n",
        "                # print(\"len(example): \", len(example))\n",
        "                # print(\"len(current_example): \", len(current_example))\n",
        "\n",
        "                # Append the current example to labels\n",
        "                labels.append(current_example)\n",
        "                attention_masks.append(attention_mask)\n",
        "\n",
        "            labels = torch.stack(labels)\n",
        "            attention_masks = torch.stack(attention_masks)\n",
        "\n",
        "\n",
        "\n",
        "            inputs = batch\n",
        "            #inputs, labels = (batch, batch)\n",
        "            if inputs.shape[1] > 1024: continue\n",
        "            inputs = inputs.to(args.device)\n",
        "            labels = labels.to(args.device)\n",
        "            attention_masks = attention_masks.to(args.device)\n",
        "            model.train()\n",
        "\n",
        "            #This is wrong, should only compute loss for the response turn, here loss is being computed for every turn\n",
        "            outputs = model(inputs, labels=labels, attention_mask = attention_masks)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            #This if updates the parameters when the step number in the current batch is a multiple of gradient_accumulation_steps\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                # Logging when the current value of global_step is a multiple of args.logging_steps\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
        "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
        "                    #This is the average loss per step\n",
        "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    checkpoint_prefix = \"checkpoint\"\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
        "                    os.makedirs(output_dir, exist_ok=True)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                    # Delete excess checkpoints\n",
        "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
        "\n",
        "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "# Evaluation of some model.\n",
        "# Need to change this to incorporate our evaluation metrics\n",
        "\n",
        "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_output_dir = args.output_dir # output-small\n",
        "\n",
        "    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n",
        "    os.makedirs(eval_output_dir, exist_ok=True)\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    # multi-gpu evaluate\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    model.eval()\n",
        "\n",
        "    labels = []\n",
        "    generated_output = []\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        # inputs, labels = (batch, batch)\n",
        "        # inputs = inputs.to(args.device)\n",
        "        # labels = labels.to(args.device)\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        #     outputs = model(inputs, labels=labels)\n",
        "        #     #print(\"Outputs: \", outputs)\n",
        "        #     lm_loss = outputs[0]\n",
        "        #     # print(\"lm_loss: \", lm_loss)\n",
        "        #     # print(\"lm_loss.item(): \",lm_loss.item() )\n",
        "        #     # print(\"lm_loss.mean().item(): \",lm_loss.mean().item() )\n",
        "\n",
        "        #     #lm_loss.mean() meaningless, not needed\n",
        "        #     eval_loss += lm_loss.mean().item()\n",
        "        # nb_eval_steps += 1\n",
        "\n",
        "        inputs = []\n",
        "        attention_masks=[]\n",
        "\n",
        "        for example in batch:\n",
        "          #print(\"Printing raw example: \", tokenizer.decode(example))\n",
        "          example = torch.flip(example,[0])\n",
        "          # Find the indices of eos_token_id in the reversed example\n",
        "          eos_indices = [i for i, x in enumerate(example) if x == tokenizer.eos_token_id]\n",
        "          # Check if there are at least two occurrences of eos_token_id\n",
        "\n",
        "          # Get the index of the second occurrence of eos_token_id\n",
        "          idx0 = eos_indices[0]\n",
        "          idx1 = eos_indices[1]\n",
        "          # Create the current example list\n",
        "          current_example = example[idx0+1:idx1]\n",
        "          # Pad the current example list with -100\n",
        "          remaining_example = example[idx1:]\n",
        "          # Reverse the current example list\n",
        "          current_example = torch.flip(current_example,[0])\n",
        "          remaining_example = torch.flip(remaining_example,[0])\n",
        "          attention_mask = torch.full((len(remaining_example),),1)\n",
        "\n",
        "          #print(\"Printing extracted label: \", tokenizer.decode(current_example))\n",
        "          if(len(current_example) ==0):\n",
        "            print(\"Empty label detected. eos_indices: \", eos_indices,\" full example: \", tokenizer.decode(torch.flip(example,[0])))\n",
        "          labels.append(current_example.tolist())\n",
        "          inputs.append(remaining_example)\n",
        "          attention_masks.append(attention_mask)\n",
        "\n",
        "        inputs = pad_sequence(inputs, batch_first = True)\n",
        "        attention_masks = pad_sequence(attention_masks, batch_first = True)\n",
        "        # print(attention_masks)\n",
        "        # print(\"Inputs: \", inputs)\n",
        "        device = torch.device(\"cuda\")\n",
        "        inputs = inputs.to(device)\n",
        "        # if(inputs.size()[-1]>1024):\n",
        "        #   print(inputs)\n",
        "        #print(\"Before: \", inputs.size())\n",
        "        attention_masks = attention_masks.to(device)\n",
        "        generated_outputs = model.generate(inputs, max_new_tokens = 50, attention_mask = attention_masks, pad_token_id=tokenizer.eos_token_id)\n",
        "        # print(\"inputs[0:3]: \", inputs[0:3])\n",
        "        # print(\"generated_outputs[0:3]: \", generated_outputs[0:3])\n",
        "        #print(\"After: \", generated_outputs.size())\n",
        "        #print(\"Before shortening: \", list(map(lambda l: tokenizer.decode(l, skip_special_tokens = True), generated_outputs )))\n",
        "        generated_outputs = list(map(lambda l1,l2: l2[len(l1):], inputs, generated_outputs))\n",
        "        #print(\"After shortening: \", list(map(lambda l: tokenizer.decode(l, skip_special_tokens = True), generated_outputs )))\n",
        "        #generated_outputs = generated_outputs.tolist()\n",
        "        generated_output = generated_output + generated_outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # eval_loss = eval_loss / nb_eval_steps\n",
        "    # perplexity = torch.exp(torch.tensor(eval_loss))\n",
        "\n",
        "    # result = {\"perplexity\": perplexity}\n",
        "\n",
        "    # cosine_sim = calculate_cosine(labels, generated_output, tokenizer)\n",
        "    # print(\"Cosine calculated\")\n",
        "\n",
        "    # print(\"Length of labels: \", len(labels))\n",
        "    # print(\"Length of generated_output\", len(generated_output))\n",
        "    # print(\"Printing labels: \", list(map(lambda l: tokenizer.decode(l, skip_special_tokens = True), labels )))\n",
        "    # print(\"Printing generated_output: \", list(map(lambda l: tokenizer.decode(l, skip_special_tokens = True), generated_output )))\n",
        "    rouge_value = calculate_rouge(labels, generated_output, tokenizer)\n",
        "    print(\"Rouge calculated\")\n",
        "    bertscore_value = calculate_bert_score(labels, generated_output, tokenizer)\n",
        "    print(\"Bertscore calculated\")\n",
        "\n",
        "    #result = {\"cosine_similarity\": cosine_sim, \"rouge_score\": rouge_value, \"bertscore\": bertscore_value}\n",
        "    result = {\"rouge_score\": rouge_value, \"bertscore\": bertscore_value}\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyaCqUAcdwc2"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda\")\n",
        "# args.n_gpu = torch.cuda.device_count()\n",
        "# args.device = device\n",
        "# model.to(args.device)\n",
        "# result = evaluate(args, model, tokenizer, trn_df, val_df, prefix=\"prefix\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMHrjS6Zqqu0"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_nKdDVazRt7"
      },
      "source": [
        "# **Main**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MGD6bFXV4Z-"
      },
      "outputs": [],
      "source": [
        "# Main runner\n",
        "\n",
        "def main(df_trn, df_val):\n",
        "    args = Args()\n",
        "\n",
        "    if args.should_continue:\n",
        "        sorted_checkpoints = _sorted_checkpoints(args)\n",
        "        if len(sorted_checkpoints) == 0:\n",
        "            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n",
        "        else:\n",
        "            args.model_name_or_path = sorted_checkpoints[-1]\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "        and not args.should_continue\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    device = torch.device(\"cuda\")\n",
        "    args.n_gpu = torch.cuda.device_count()\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    config = AutoConfig.from_pretrained(args.config_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=False,\n",
        "        config=config,\n",
        "    )\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n",
        "\n",
        "        t1 = time.time()\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "        t2 = time.time()\n",
        "        os.makedirs(os.path.join(args.output_dir, 'results'), exist_ok = True)\n",
        "        loggingfilepath = os.path.join(args.output_dir, \"results/time_results.txt\")\n",
        "        with open(loggingfilepath, \"w\") as file:\n",
        "          # Write some text to the file\n",
        "          file.write(\"Training time: \" + str(t2-t1))\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
        "    if args.do_train:\n",
        "        # Create output directory if needed\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = (\n",
        "            model.module if hasattr(model, \"module\") else model\n",
        "        )  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(args.output_dir)\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        model = AutoModelForCausalLM.from_pretrained(args.output_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSeyFrjSzYZ9"
      },
      "outputs": [],
      "source": [
        "def evaluation_caller(df_val, df_trn, setting):\n",
        "    device = torch.device(\"cuda\")\n",
        "    args.n_gpu = torch.cuda.device_count()\n",
        "    args.device = device\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        t1 = time.time()\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "            tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "            #tokenizer.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "        t2 = time.time()\n",
        "        os.makedirs(os.path.join(args.output_dir, 'results'), exist_ok = True)\n",
        "        logpath = os.path.join(args.output_dir,'results/evaluation_time.txt')\n",
        "        with open(logpath, \"a\") as file:\n",
        "          # Write some text to the file\n",
        "          file.write(\"\\nEvaluation time of \" + setting + \": \" + str(t2-t1))\n",
        "\n",
        "        respath = os.path.join(args.output_dir,'results/evaluation_results.txt')\n",
        "        with open(respath, \"a\") as file:\n",
        "          # Write some text to the file\n",
        "          file.write(\"Evaluation results of: \" + setting + \": \" + str(results))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEHDzR0Vjs7"
      },
      "source": [
        "It is time to train our model!\n",
        "\n",
        "![alt text](https://media.giphy.com/media/Tia3dkakIp2m4uGoDI/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Naf2xu1wzQn_"
      },
      "outputs": [],
      "source": [
        "trn_df = torch.load('/content/drive/MyDrive/RolePlay/trainset.pkl')\n",
        "\n",
        "BD_SC1_val_df = torch.load('/content/drive/MyDrive/RolePlay/BD_SC1_val.pkl')\n",
        "BD_SC2_val_df = torch.load('/content/drive/MyDrive/RolePlay/BD_SC2_val.pkl')\n",
        "HC_SC1_val_df = torch.load('/content/drive/MyDrive/RolePlay/HC_SC1_val.pkl')\n",
        "HC_SC2_val_df = torch.load('/content/drive/MyDrive/RolePlay/HC_SC2_val.pkl')\n",
        "SZ_SC1_val_df = torch.load('/content/drive/MyDrive/RolePlay/SZ_SC1_val.pkl')\n",
        "SZ_SC2_val_df = torch.load('/content/drive/MyDrive/RolePlay/SZ_SC2_val.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__iqR8YFV-Ex"
      },
      "outputs": [],
      "source": [
        "#Call main to train model\n",
        "main(trn_df, BD_SC1_val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVLVFIMmP3_p"
      },
      "outputs": [],
      "source": [
        "print(\"Final result of BD Scene1: \", evaluation_caller(BD_SC1_val_df, trn_df, \"BD Scene 1\"))\n",
        "print(\"Final result of BD Scene2: \", evaluation_caller(BD_SC2_val_df, trn_df, \"BD Scene 2\"))\n",
        "print(\"Final result of HC Scene1: \", evaluation_caller(HC_SC1_val_df, trn_df, \"HC Scene 1\"))\n",
        "print(\"Final result of HC Scene2: \", evaluation_caller(HC_SC2_val_df, trn_df, \"HC Scene 2\"))\n",
        "print(\"Final result of SZ Scene1: \", evaluation_caller(SZ_SC1_val_df, trn_df, \"SZ Scene 1\"))\n",
        "print(\"Final result of SZ Scene2: \", evaluation_caller(SZ_SC2_val_df, trn_df, \"SZ Scene 2\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eDkPEuvbD47"
      },
      "source": [
        "## Chatting with  LLM assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjVqotI05gOS"
      },
      "source": [
        "The model is ready, so it's time to chat with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIeqMwZktv7N"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "model = AutoModelForCausalLM.from_pretrained('output-small')\n",
        "\n",
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "    # print(new_user_input_ids)\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens,\n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, max_length=200,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=3,\n",
        "        do_sample=True,\n",
        "        top_k=100,\n",
        "        top_p=0.7,\n",
        "        temperature = 0.8\n",
        "    )\n",
        "\n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"Bot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c221c0b37db4215bc643f6055959ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e6666dd508f4dd280fbcac25778267e",
              "IPY_MODEL_bb8b0f6f3f41462b87e21e539b475b6e",
              "IPY_MODEL_346e4c93a18b496dbf37367a6ae4ff92"
            ],
            "layout": "IPY_MODEL_b69cdbac44584017a32321486aea087b"
          }
        },
        "2e6666dd508f4dd280fbcac25778267e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_602d24ba13aa4abd856d480ad0d32668",
            "placeholder": "​",
            "style": "IPY_MODEL_16f27aef8dbf42eeae0794f48fddef3c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bb8b0f6f3f41462b87e21e539b475b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce8d746d74ac492882ab0783a29e8ff1",
            "max": 1289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23e444a2f11e4b418ae433865fc046f3",
            "value": 1289
          }
        },
        "346e4c93a18b496dbf37367a6ae4ff92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e868357bc8145629fc52473e877053c",
            "placeholder": "​",
            "style": "IPY_MODEL_510e99d041d54ccaa522f7acae015131",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "b69cdbac44584017a32321486aea087b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602d24ba13aa4abd856d480ad0d32668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f27aef8dbf42eeae0794f48fddef3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce8d746d74ac492882ab0783a29e8ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23e444a2f11e4b418ae433865fc046f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e868357bc8145629fc52473e877053c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510e99d041d54ccaa522f7acae015131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f55ecaeb591e4279a00f472d64f8cbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2367396960a4be3a83a2b3dc6e3544f",
              "IPY_MODEL_aede6c3349e3468fac56f9a035accfb2",
              "IPY_MODEL_893551ca19a4483895978e6173c1e81d"
            ],
            "layout": "IPY_MODEL_142c80ea19784b309a3116ecda843886"
          }
        },
        "c2367396960a4be3a83a2b3dc6e3544f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_442a48e64e584eacab67e84ebd66d304",
            "placeholder": "​",
            "style": "IPY_MODEL_9420aef7ff904c148e051bb5ddd66636",
            "value": "tokenizer.model: 100%"
          }
        },
        "aede6c3349e3468fac56f9a035accfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2233df4925a4553b4f7db0a27a08ac8",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_538db49a4a1c44c199f185802f2c4c18",
            "value": 499723
          }
        },
        "893551ca19a4483895978e6173c1e81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613afcfec84c40828ca5f3622d321772",
            "placeholder": "​",
            "style": "IPY_MODEL_5cf307b69ed046edb014f783daeb9803",
            "value": " 500k/500k [00:00&lt;00:00, 8.11MB/s]"
          }
        },
        "142c80ea19784b309a3116ecda843886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442a48e64e584eacab67e84ebd66d304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9420aef7ff904c148e051bb5ddd66636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2233df4925a4553b4f7db0a27a08ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538db49a4a1c44c199f185802f2c4c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "613afcfec84c40828ca5f3622d321772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf307b69ed046edb014f783daeb9803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bcb3976d6794529841869fce0d6feb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cdfa2a0419d40499889314422bd30f0",
              "IPY_MODEL_6b2a40af5a254cd5abb71158d566dcba",
              "IPY_MODEL_9b5fcc7dbd934ca78fb3933387e9e571"
            ],
            "layout": "IPY_MODEL_494a4a35a83f454e93d7f0dae95416d7"
          }
        },
        "4cdfa2a0419d40499889314422bd30f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdf8c4c535349cc94c66686ef0c508a",
            "placeholder": "​",
            "style": "IPY_MODEL_abdadf94f9094da9a616af92377e69b8",
            "value": "tokenizer.json: 100%"
          }
        },
        "6b2a40af5a254cd5abb71158d566dcba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b0a7922b94b4f5eb74fd15b383dd393",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22fe5170eb23495e8bbc6be40e4bdfcf",
            "value": 1842767
          }
        },
        "9b5fcc7dbd934ca78fb3933387e9e571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab3188243444284a45a67add4ee3e60",
            "placeholder": "​",
            "style": "IPY_MODEL_454e112dce4a43938d3aa0854b6f29a9",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 24.4MB/s]"
          }
        },
        "494a4a35a83f454e93d7f0dae95416d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfdf8c4c535349cc94c66686ef0c508a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abdadf94f9094da9a616af92377e69b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b0a7922b94b4f5eb74fd15b383dd393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fe5170eb23495e8bbc6be40e4bdfcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ab3188243444284a45a67add4ee3e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454e112dce4a43938d3aa0854b6f29a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ecce3f871b410fad5c8bcd86add663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ec5d0fb8c70445798d7ffe90974e07e",
              "IPY_MODEL_ccca28c7fd72491a80d81f1b490291af",
              "IPY_MODEL_2187193846674d2bb377bf614e5eedc8"
            ],
            "layout": "IPY_MODEL_15b12e98180e49b0a309e7369b70bfeb"
          }
        },
        "4ec5d0fb8c70445798d7ffe90974e07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b338d2f1e524d1e908be0e2c0289c64",
            "placeholder": "​",
            "style": "IPY_MODEL_d806ddc558f5411aba99813a5eaf8853",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ccca28c7fd72491a80d81f1b490291af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0347e50d2e124b71882437f0703be8cd",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aad5d4d487084ebf9d025549ea89328a",
            "value": 551
          }
        },
        "2187193846674d2bb377bf614e5eedc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3dd1fe1311047feb837b512a47979ea",
            "placeholder": "​",
            "style": "IPY_MODEL_472639a75c6f4316872fdc3f802c7d66",
            "value": " 551/551 [00:00&lt;00:00, 48.5kB/s]"
          }
        },
        "15b12e98180e49b0a309e7369b70bfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b338d2f1e524d1e908be0e2c0289c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d806ddc558f5411aba99813a5eaf8853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0347e50d2e124b71882437f0703be8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad5d4d487084ebf9d025549ea89328a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3dd1fe1311047feb837b512a47979ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472639a75c6f4316872fdc3f802c7d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31edf74da1924269a7a0169dec572eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f38a4b6754b54c64a82957b7b7ac0e56",
              "IPY_MODEL_be89d71b7ccf4322923811ce6122baad",
              "IPY_MODEL_90ce1fee6c32460c8b99048355009df3"
            ],
            "layout": "IPY_MODEL_cb9b69474c464e06b46a9361c7d18670"
          }
        },
        "f38a4b6754b54c64a82957b7b7ac0e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa315336cf0143efbd4c16dc1e452713",
            "placeholder": "​",
            "style": "IPY_MODEL_1d293b58999b45d8bc14491f91b8872d",
            "value": "config.json: 100%"
          }
        },
        "be89d71b7ccf4322923811ce6122baad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8de0a128a43403486b76c928dd27fdd",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d88a0439e914e5aacb6765db7fb5df1",
            "value": 608
          }
        },
        "90ce1fee6c32460c8b99048355009df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3189e87a6b24de7b194ae4d326a89fa",
            "placeholder": "​",
            "style": "IPY_MODEL_ced90b7400814f3f8c4e54b683fa0d13",
            "value": " 608/608 [00:00&lt;00:00, 51.2kB/s]"
          }
        },
        "cb9b69474c464e06b46a9361c7d18670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa315336cf0143efbd4c16dc1e452713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d293b58999b45d8bc14491f91b8872d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8de0a128a43403486b76c928dd27fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d88a0439e914e5aacb6765db7fb5df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3189e87a6b24de7b194ae4d326a89fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced90b7400814f3f8c4e54b683fa0d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81e10855a3c049b58d09fd2b2aa4696c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff1bc73d07f449a8bbdffc88c9270b5e",
              "IPY_MODEL_cbbe6b84de3f4f5abc0063a66efac187",
              "IPY_MODEL_01d4765b90dc4d10bc01ce9df1cf3c86"
            ],
            "layout": "IPY_MODEL_bec7560c6094471abca139493113abdd"
          }
        },
        "ff1bc73d07f449a8bbdffc88c9270b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dca9eb853dc4103a18b46d62dc1bb19",
            "placeholder": "​",
            "style": "IPY_MODEL_d7206b2d41df45c797c9f1170a3dcb70",
            "value": "model.safetensors: 100%"
          }
        },
        "cbbe6b84de3f4f5abc0063a66efac187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd8e0a3ea0d46ecb7d58058582e4257",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_529defb66b284c11ae1b3fa5ad6de96b",
            "value": 2200119864
          }
        },
        "01d4765b90dc4d10bc01ce9df1cf3c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb557be85e94afd890d6e7cdbded5e0",
            "placeholder": "​",
            "style": "IPY_MODEL_f7bd35bfad384344befdc26c28722d57",
            "value": " 2.20G/2.20G [00:10&lt;00:00, 215MB/s]"
          }
        },
        "bec7560c6094471abca139493113abdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dca9eb853dc4103a18b46d62dc1bb19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7206b2d41df45c797c9f1170a3dcb70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd8e0a3ea0d46ecb7d58058582e4257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529defb66b284c11ae1b3fa5ad6de96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abb557be85e94afd890d6e7cdbded5e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7bd35bfad384344befdc26c28722d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faf803620b0b4954b4961b8a00e1c95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_676b70b05d5741d0b233ea687e4e3642",
              "IPY_MODEL_12f3f95332204c5d970bf9d202ff6f33",
              "IPY_MODEL_f04d81c2aebc48fbb62511566761de13"
            ],
            "layout": "IPY_MODEL_b6a90c5735f34d57810a97dc01a33e08"
          }
        },
        "676b70b05d5741d0b233ea687e4e3642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff52187f931848e7a6117a8092227292",
            "placeholder": "​",
            "style": "IPY_MODEL_66a6200111604397b1870842dbcd77f8",
            "value": "generation_config.json: 100%"
          }
        },
        "12f3f95332204c5d970bf9d202ff6f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8616d0455a24a098b79b0df93d34072",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42326deb23a445b5b697d7af7a9822e7",
            "value": 124
          }
        },
        "f04d81c2aebc48fbb62511566761de13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1b5813833349568d54399c0792ae6b",
            "placeholder": "​",
            "style": "IPY_MODEL_69f21fe2809b42bf8d945755dc7161e7",
            "value": " 124/124 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "b6a90c5735f34d57810a97dc01a33e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff52187f931848e7a6117a8092227292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a6200111604397b1870842dbcd77f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8616d0455a24a098b79b0df93d34072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42326deb23a445b5b697d7af7a9822e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac1b5813833349568d54399c0792ae6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f21fe2809b42bf8d945755dc7161e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}