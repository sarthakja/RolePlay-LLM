Evaluation results of: 
BD Scene 1: rouge_score: {'rouge1_fmeasure': 0.0426, 'rouge1_precision': 0.0597, 'rouge1_recall': 0.0479, 'rougeL_fmeasure': 0.0424, 'rougeL_precision': 0.0594, 'rougeL_recall': 0.0478}, 'bertscore_': {'precision': 0.15927629043226657, 'recall': 0.1528648269781168, 'f1': 0.15538548235444055, }
Evaluation results of: BD Scene 2: 'rouge1_fmeasure': 0.1331, 'rouge1_precision': 0.1490, 'rouge1_recall': 0.1317, 'rougeL_fmeasure': 0.1304, 'rougeL_precision': 0.1464, 'rougeL_recall': 0.1284, 'bertscore_': {'precision': 0.26441786504454085, 'recall': 0.2582374008993308, 'f1': 0.2606273278594017
Evaluation results of: HC Scene 1: {'rouge_score_': {'rouge1_fmeasure': 0.0497), 'rouge1_precision': (0.0625), 'rouge1_recall': (0.0595), 'rougeL_fmeasure': (0.0493), 'rougeL_precision': (0.0622), 'rougeL_recall': (0.0590)}, 'bertscore_': {'precision': 0.14982112805048625, 'recall': 0.14788515686988832, 'f1': 0.1483380870024363
Evaluation results of: HC Scene 2: {'rouge_score_': {'rouge1_fmeasure': (0.1188), 'rouge1_precision': (0.1288), 'rouge1_recall': (0.1358), 'rougeL_fmeasure': (0.1153), 'rougeL_precision': (0.1246), 'rougeL_recall': (0.1321)}, 'bertscore_': {'precision': 0.23798964137122744, 'recall': 0.2376443530832018, 'f1': 0.23703074341728575
Evaluation results of: SZ Scene 1: {'rouge_score_': {'rouge1_fmeasure': (0.0417), 'rouge1_precision': (0.0618), 'rouge1_recall': (0.0407), 'rougeL_fmeasure': (0.0417), 'rougeL_precision': (0.0618), 'rougeL_recall': (0.0407)}, 'bertscore_': {'precision': 0.167466783172944, 'recall': 0.15930344953256495, 'f1': 0.1627047888204163
Evaluation results of: SZ Scene 2: {'rouge_score_': {'rouge1_fmeasure': (0.1283), 'rouge1_precision': (0.1536), 'rouge1_recall': (0.1264), 'rougeL_fmeasure': (0.1272), 'rougeL_precision': (0.1522), 'rougeL_recall': (0.1254)}, 'bertscore_': {'precision': 0.2604100015540581, 'recall': 0.2523573456847735, 'f1': 0.25566508557836887
